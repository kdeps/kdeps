apiVersion: kdeps.io/v1
kind: Resource

metadata:
  actionId: llmResource
  name: LLM Chat

run:
  restrictToHttpMethods: [POST]
  restrictToRoutes: [/api/v1/chat]

  preflightCheck:
    validations:
      - get('q') != ''
    error:
      code: 400
      message: Query parameter 'q' is required

  chat:
    backend: ollama
    model: llama3.2:1b
    role: user
    prompt: "{{ get('q') }}"
    scenario:
      - role: assistant
        prompt: You are a helpful AI assistant.
    jsonResponse: true
    jsonResponseKeys:
      - answer
    timeoutDuration: 60s
